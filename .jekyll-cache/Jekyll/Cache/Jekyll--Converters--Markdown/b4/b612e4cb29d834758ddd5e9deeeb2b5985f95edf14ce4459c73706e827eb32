I"µ<p>ä¸Šä¸€ç¯‡æ–‡ç« ä¸­æˆ‘ä»¬ç”¨PyTorchå®ç°äº†ä¸€ä¸ªçº¿æ€§å›å½’çš„æ¨¡å‹ï¼Œè¿™ç¯‡æ–‡ç« æˆ‘ä»¬å°†ç”¨ç¥ç»ç½‘ç»œæ¥é‡æ–°è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ã€‚è™½ç„¶æˆ‘ä»¬åªæœ‰ä¸€ä¸ªfeatureå’Œæä¸ºå°‘é‡çš„è®­ç»ƒæ ·æœ¬ï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œä¸å…æœ‰äº›OverKilläº†ï¼Œä½†ä½¿ç”¨ç¥ç»ç½‘ç»œçš„ä¸€ä¸ªæœ‰è¶£ä¹‹å¤„æ˜¯æˆ‘ä»¬ä¸çŸ¥é“å®ƒæœ€åä¼šå¸®æˆ‘ä»¬æ‹Ÿåˆå‡ºçš„ä»€ä¹ˆæ ·çš„æ¨¡å‹ã€‚</p>

<p>æˆ‘ä»¬ä¸‹é¢ä¼šç”¨PyTorchæ­å»ºä¸¤ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œæ¥é‡æ–°æ‹Ÿåˆä¸Šä¸€ç¯‡æ–‡ç« ä¸­çš„æ¨¡å‹ï¼Œæœ€åæˆ‘ä»¬ä¼šåšä¸€ä¸ªç¨å¾®å¤æ‚ä¸€ç‚¹çš„å…¨FCç½‘ç»œåšå›¾ç‰‡åˆ†ç±»ã€‚</p>

<h3 id="ä¸€ä¸ªç¥ç»å…ƒçš„ç¥ç»ç½‘ç»œ">ä¸€ä¸ªç¥ç»å…ƒçš„ç¥ç»ç½‘ç»œ</h3>

<p>PyTorchä¸­ç¥ç»ç½‘ç»œç›¸å…³çš„layerç§°ä¸ºmoduleï¼Œå°è£…åœ¨<code class="highlighter-rouge">torch.nn</code>ä¸­ï¼Œç”±äºæˆ‘ä»¬çš„æ¨¡å‹æ˜¯çº¿æ€§çš„ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨<code class="highlighter-rouge">nn.Linear</code>è¿™ä¸ªmoduleï¼Œæ­¤å¤–ç”±äºæˆ‘ä»¬çš„ä¾‹å­ä¸­åªæœ‰ä¸€ä¸ªfeatureï¼ŒåŠ ä¸Šæˆ‘çš„è¾“å‡ºä¹Ÿæ˜¯ä¸€ä¸ªå€¼ï¼Œå› æ­¤æˆ‘ä»¬çš„ç¥ç»ç½‘ç»œå®é™…ä¸Šåªæœ‰ä¸€ä¸ªç¥ç»å…ƒï¼Œè¾“å…¥æ˜¯ä¸€ä¸ªtensorï¼Œè¾“å‡ºä¹Ÿæ˜¯ä¸€ä¸ªtensorã€‚</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>

<span class="n">t_x</span> <span class="o">=</span> <span class="p">[</span><span class="mf">35.7</span><span class="p">,</span> <span class="mf">55.9</span><span class="p">,</span> <span class="mf">58.2</span><span class="p">,</span> <span class="mf">81.9</span><span class="p">,</span> <span class="mf">56.3</span><span class="p">,</span> <span class="mf">48.9</span><span class="p">,</span> <span class="mf">33.9</span><span class="p">,</span> <span class="mf">21.8</span><span class="p">,</span> <span class="mf">48.4</span><span class="p">,</span> <span class="mf">60.4</span><span class="p">,</span> <span class="mf">68.4</span><span class="p">]</span>
<span class="n">t_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">t_x</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="c1">#convert t_x to [11x1]
</span><span class="n">t_xn</span> <span class="o">=</span> <span class="n">t_x</span><span class="o">*</span><span class="mf">0.1</span>

<span class="n">linear_model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">linear_model</span><span class="p">(</span><span class="n">t_xn</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</code></pre></div></div>
<p>ä¸Šè¿°ä»£ç ä¸­æˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ª<code class="highlighter-rouge">linear_model</code>ï¼Œè¿™ä¸ªmodelåªæœ‰ä¸€ä¸ªç¥ç»å…ƒï¼Œè¾“å…¥å’Œè¾“å‡ºåªæœ‰ä¸€ä¸ªtensorã€‚æ¥ç€æˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ª<code class="highlighter-rouge">11x1</code>çš„input tensorã€‚ç”±äºæˆ‘ä»¬çš„modelæ²¡æœ‰ç»è¿‡è®­ç»ƒï¼Œå› æ­¤è¾“å‡ºä¸ºä¸€å †æ— æ„ä¹‰çš„tensorã€‚é»˜è®¤æƒ…å†µä¸‹<code class="highlighter-rouge">nn.Linear</code>åŒ…å«biasï¼Œè€Œweightå€¼è¢«åˆå§‹åŒ–ä¸ºä¸€ä¸ªéšæœºæ•°</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">"weight: "</span><span class="p">,</span><span class="n">linear_model</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span> <span class="c1">#tensor([[-0.1335]], requires_grad=True)
</span><span class="k">print</span><span class="p">(</span><span class="s">"bias: "</span><span class="p">,</span><span class="n">linear_model</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span> <span class="c1">#tensor([-0.4349], requires_grad=True)
</span></code></pre></div></div>
<p>æ¥ä¸‹æ¥æˆ‘ä»¬å‚è€ƒä¸Šä¸€ç¯‡æ–‡ç« æ¥è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">linear_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">train_loop</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>    
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">t_p</span> <span class="o">=</span> <span class="n">linear_model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t_p</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">'Epoch: {epoch}, Loss: {float(loss)}'</span><span class="p">)</span>
</code></pre></div></div>
<p>ä¸Šè¿°ä»£ç ä¸­å’Œå‰ä¸€èŠ‚å¤§åŒå°å¼‚ï¼Œæœ‰ä¸‹é¢å‡ ç‚¹å€¼å¾—æ³¨æ„</p>

<ol>
  <li>å¾…è®­ç»ƒå‚æ•°$\omega$å’Œ$b$ä¿å­˜åœ¨<code class="highlighter-rouge">linear_model.parameters()</code>ä¸­</li>
  <li>ç”±äºparamsä¿å­˜åœ¨äº†modelä¸­ï¼Œå› æ­¤PyTorchçŸ¥é“å¦‚ä½•updateè¿™äº›å‚æ•°ï¼Œä¸å†éœ€è¦æˆ‘ä»¬æ‰‹åŠ¨ç¼–å†™æ¢¯åº¦ä¸‹é™çš„ä»£ç </li>
  <li>losså‡½æ•°ä½¿ç”¨ç³»ç»Ÿè‡ªå¸¦çš„<code class="highlighter-rouge">nn.MSELoss</code>å¯¹åº”ä¸Šä¸€èŠ‚çš„L2 losså‡½æ•°</li>
</ol>

<p>ç”±äºæˆ‘ä»¬çš„<code class="highlighter-rouge">linear_module</code>åœ¨æ•°å­¦ä¸Šå°±æ˜¯åœ¨è®¡ç®—$y = \omega x + b$ï¼Œæˆ‘ä»¬å¯ä»¥çŒœåˆ°è®­ç»ƒç»“æœå’Œå‰æ–‡æ˜¯ä¸€è‡´çš„</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_loop</span><span class="p">(</span><span class="mi">3000</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(),</span><span class="n">t_xn</span><span class="p">,</span> <span class="n">t_y</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"params:"</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">linear_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()))</span>
<span class="c1">#tensor([[5.3491]], requires_grad=True), Parameter containing:
#tensor([-17.1995], requires_grad=True)]
</span></code></pre></div></div>
<p>è®­ç»ƒç»“æœç¬¦åˆæˆ‘ä»¬é¢„æœŸï¼Œè¡¨é¢ä¸Šçœ‹è¿™ä¸ªä¾‹å­å¥½åƒæ²¡ä»€ä¹ˆæ„ä¹‰ï¼Œä½†å®ƒå‘Šè¯‰æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ç¥ç»ç½‘ç»œæ¥è®­ç»ƒçº¿æ€§å›å½’æ¨¡å‹ï¼Œåœ¨ä¸‹ä¸€èŠ‚æˆ‘ä»¬å°†ç»§ç»­æ”¹è¿›åœ¨è¿™ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œã€‚</p>

<h3 id="éçº¿æ€§æ¨¡å‹">éçº¿æ€§æ¨¡å‹</h3>

<p>ä¸ºäº†æ›´ç²¾å‡†çš„æ‹Ÿåˆæ•°æ®ï¼Œæˆ‘ä»¬å¯ä»¥é‡‡ç”¨éçº¿æ€§æ¨¡å‹ï¼Œæ¯”å¦‚é«˜é˜¶çš„çº¿æ€§å›å½’ï¼Œä½†ä¸å…¶æ‰‹åŠ¨çš„å®šä¹‰æ¨¡å‹ï¼Œæˆ‘ä»¬è¿˜æ˜¯ç”¨ç¥ç»ç½‘ç»œå¸®æˆ‘ä»¬å¯»æ‰¾è¿™ä¸ªæ¨¡å‹ã€‚ä¸åŒçš„æ˜¯è¿™æ¬¡æˆ‘ä»¬è¦å¯¹æ•°æ®åšä¸€äº›éçº¿æ€§å˜æ¢ï¼Œå…·ä½“æ¥è¯´æ˜¯å¼•å…¥ä¸€ä¸ªhidder layerå’Œactivationå‡½æ•°ã€‚æˆ‘ä»¬æ–°çš„modelç»“æ„å¦‚ä¸‹</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">seq_model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">13</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">13</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>

<span class="k">print</span><span class="p">(</span><span class="n">seq_model</span><span class="p">)</span>
<span class="c1"># Sequential(
#   (0): Linear(in_features=1, out_features=13, bias=True)
#   (1): Tanh()
#   (2): Linear(in_features=13, out_features=1, bias=True)
# )
</span></code></pre></div></div>
<p>ä¸Šè¿°ä»£ç ä¸­æˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ª<code class="highlighter-rouge">[1,13]</code>çš„hidden layerï¼Œç„¶åè·Ÿäº†ä¸€ä¸ª<code class="highlighter-rouge">Tanh()</code>çš„éçº¿æ€§å˜æ¢ä½œä¸ºactivationå‡½æ•°ï¼Œæœ€åçš„output layeråˆæŠŠç»“æœå˜æˆ<code class="highlighter-rouge">[1,1]</code>çš„tensorï¼Œæ•´ä¸ªmodelçš„ç»“æ„å¦‚ä¸‹å›¾æ‰€ç¤º</p>

<p><img class="md-img-center" src="/assets/images/2019/07/pytorch-1.png" /></p>

<p>æ˜¾ç„¶ç›¸æ¯”äºå‰é¢çš„æ¨¡å‹ï¼Œè¿™ä¸ªæ¨¡å‹ç•¥å¾®å¤æ‚äº†ä¸€äº›ã€‚åœ¨è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆæ¥åˆ†æä¸‹æœ‰å¤šå°‘ä¸ªå¾…å­¦ä¹ å‚æ•°ã€‚å¯¹äºhidden layeræˆ‘ä»¬æœ‰13ä¸ª$\omega$ï¼Œ13ä¸ª$b$ï¼Œå¯¹äºoutput layerï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ª$\omega$å’Œä¸€ä¸ª$b$ã€‚å› æ­¤ä¸€å…±æœ‰28ä¸ªå¾…å­¦ä¹ çš„å‚æ•°ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ç”¨ä¸‹é¢ä»£ç æ¥æŸ¥çœ‹</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">name</span><span class="p">,</span><span class="n">param</span> <span class="ow">in</span> <span class="n">seq_model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># 0.weight torch.Size([13, 1])
# 0.bias torch.Size([13])
# 2.weight torch.Size([1, 13])
# 2.bias torch.Size([1])
</span></code></pre></div></div>
<p>ä¸Šè¿°ä»£ç ä¼šæ‰“å°å‡ºæ•´ä¸ªnetworkä¸­å¾…å­¦ä¹ çš„å‚æ•°ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬ç”¨åŒæ ·çš„æ€è·¯è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">seq_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">train_loop</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>    
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">t_p</span> <span class="o">=</span> <span class="n">seq_model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t_p</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">'Epoch: {epoch}, Loss: {float(loss)}'</span><span class="p">)</span>

<span class="n">train_loop</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(),</span><span class="n">t_xn</span><span class="p">,</span> <span class="n">t_y</span><span class="p">)</span>
</code></pre></div></div>
<p>åœ¨5000æ¬¡è¿­ä»£åï¼Œlossæ”¶æ•›åœ¨1.950253963470459ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬æ¥å¯è§†åŒ–ä¸€ä¸‹æˆ‘ä»¬modelå¹¶è§‚å¯Ÿé¢„æµ‹ç»“æœ</p>

<div class="md-flex-h md-flex-no-wrap md-margin-bottom-12">
<div><img src="/assets/images/2019/06/pytorch-lr-1.png" /></div>
<div class="md-margin-left-12"><img src="/assets/images/2019/07/pytorch-2.png" /></div>
</div>

<blockquote>
  <p>ä¸Šå›¾ä¸­å®å¿ƒçš„ç‚¹ä¸ºæˆ‘ä»¬çš„åŸå§‹æ•°æ®ï¼Œç»¿è‰²çš„æ›²çº¿æ˜¯ç¥ç»ç½‘ç»œæ‹Ÿåˆå‡ºçš„æ›²çº¿ï¼Œæ ‡è®°ä¸ºxçš„ç‚¹ä¸ºé¢„æµ‹å€¼ã€‚</p>
</blockquote>

<p>å¯è§ç›¸æ¯”äºä¸Šä¸€èŠ‚çš„çº¿æ€§æ¨¡å‹ï¼Œæˆ‘ä»¬è®­ç»ƒå‡ºäº†ä¸€ä¸ªéçº¿æ€§çš„é¢„æµ‹å‡½æ•°ï¼Œä½†å®é™…ä¸Šæˆ‘ä»¬å¹¶ä¸çŸ¥é“è¿™ä¸ªå‡½æ•°çš„å…·ä½“å…¬å¼æ˜¯æ€æ ·çš„ï¼ˆè™½ç„¶æˆ‘ä»¬å¯ä»¥å¼ºè¡Œå°†ç¥ç»ç½‘ç»œå±•å¼€ï¼Œä½†æ˜¯æ²¡æœ‰å¿…è¦ï¼Œæˆ‘ä»¬åªçŸ¥é“æˆ‘ä»¬è®­ç»ƒäº†28ä¸ªå‚æ•°ï¼Œè¿™ä¹Ÿæ˜¯ç¥ç»ç½‘ç»œæ¯”è¾ƒç¥å¥‡çš„åœ°æ–¹ã€‚æ­¤å¤–æˆ‘ä»¬çš„hidden layeræœ‰13ä¸ªneuronï¼Œè¿™ä¸ªå€¼æ˜¯éšæ„æŒ‡å®šçš„ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥å°è¯•å¢åŠ æ›´å¤šçš„hidden layerå’Œè°ƒæ•´æ¯ä¸ªlayerçš„ç¥ç»å…ƒæ•°é‡æ¥è¾¾åˆ°æ›´ç²¾å‡†çš„æ‹Ÿåˆã€‚</p>

<p>å°ç»“ä¸€ä¸‹ï¼Œè¿™ä¸€èŠ‚æˆ‘ä»¬ç”¨PyTorchæ„å»ºäº†ä¸€ä¸ªä¸¤å±‚çš„ç¥ç»ç½‘ç»œï¼Œè®­ç»ƒäº†ä¸€ä¸ªéçº¿æ€§æ¨¡å‹ï¼Œè§£å†³äº†ä¸€ä¸ªç®€å•çš„å›å½’é—®é¢˜ã€‚ä½†ä¸Šè¿°ç½‘ç»œè¿˜æ˜¯æœ‰äº›ç®€å•ï¼Œåœ¨ä¸‹é¢ä¸€èŠ‚ä¸­æˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªç¨å¾®å¤æ‚ä¸€ç‚¹çš„ç½‘ç»œæ¥è§£å†³åˆ†ç±»é—®é¢˜ã€‚</p>

<h3 id="fashion-mnist">Fashion MNIST</h3>

<p>è¿™ä¸€èŠ‚æˆ‘ä»¬æ¥è®¾è®¡ä¸€ä¸ªç¨å¾®å¤æ‚ä¸€ç‚¹çš„ç¥ç»ç½‘ç»œæ¥è§£å†³å›¾åƒè¯†åˆ«çš„é—®é¢˜ï¼Œæˆ‘ä»¬è¦ç”¨çš„æ•°æ®é›†æ˜¯<a href="https://github.com/zalandoresearch/fashion-mnist">Fashion MNIST</a>ã€‚æ•°æ®é›†ä¸­çš„æ¯ä¸ªå›¾ç‰‡å‡ä¸º<code class="highlighter-rouge">(28 * 28)</code>çš„ç°åº¦å›¾ç‰‡ï¼Œé¦–å…ˆæˆ‘ä»¬æ¥å‡†å¤‡æ•°æ®</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span>
<span class="c1"># Define a transform to normalize the data
</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                                <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,))])</span>
<span class="c1"># Download and load the training data
</span><span class="n">trainset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span><span class="s">'./F_MNIST_data/'</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
<span class="n">trainloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">trainset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Download and load the test data
</span><span class="n">testset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span><span class="s">'./F_MNIST_data/'</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
<span class="n">testloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">testset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>
<p>ä¸Šè¿°<code class="highlighter-rouge">trainloader</code>ä¸­åŒ…å«äº†è®­ç»ƒç”¨çš„å›¾ç‰‡æ–‡ä»¶å’Œæ ‡æ³¨ï¼Œ<code class="highlighter-rouge">testloader</code>å­˜æ”¾æˆ‘ä»¬çš„æµ‹è¯•æ•°æ®ã€‚<code class="highlighter-rouge">transform</code>çš„ä½œç”¨æ˜¯å¯¹æ ·æœ¬æ•°æ®åšNormalizationã€‚æ¥ä¸‹æ¥æˆ‘ä»¬éå†ä¸€ä¸‹trainloaderï¼Œè§‚å¯Ÿè®­ç»ƒæ•°æ®çš„å°ºå¯¸</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trainloader</span><span class="p">))</span> <span class="c1">#938
</span><span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">lable</span> <span class="ow">in</span> <span class="n">trainloader</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1">#torch.Size([64, 1, 28, 28])
</span>    <span class="k">print</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1">#torch.Size([64])
</span></code></pre></div></div>
<p>å¯ä»¥çœ‹åˆ°æˆ‘ä»¬çš„è®­ç»ƒé›†åŒ…å«938ç»„è®­ç»ƒæ ·æœ¬ï¼Œæ¯ç»„æ ·æœ¬çš„shapeä¸º<code class="highlighter-rouge">[64,1,28,28]</code>ï¼Œè¡¨ç¤ºæ¯ç»„64å¼ å›¾ç‰‡ï¼Œæ¯å¼ å›¾åªæœ‰ä¸€ä¸ªchannelï¼Œé•¿å®½å‡ä¸º28åƒç´ ã€‚</p>

<p>å¯¹äºæ¯ä¸€å¼ å›¾ç‰‡æ¥è¯´ï¼Œç”±äºæ˜¯ç°åº¦å›¾ç‰‡ï¼Œåªæœ‰ä¸€ä¸ªé€šé“ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥å°†è¾“å…¥çš„å›¾ç‰‡ç­‰ä»·ä¸ºä¸€ä¸ª<code class="highlighter-rouge">[1x784]</code>çš„ä¸€ç»´å‘é‡ï¼Œfeatureæ•°é‡ä¸ºåƒç´ ç‚¹çš„ä¸ªæ•°ã€‚ç”±äºfeatureæ•°é‡å¹¶æ²¡æœ‰å¾ˆå¤§ï¼Œæˆ‘ä»¬ä¸éœ€è¦å¼•å…¥å·ç§¯ç¥ç»ç½‘ç»œï¼Œä½¿ç”¨è‹¥å¹²å±‚Fully Connected Layerï¼ˆåé¢ç®€ç§°FCï¼‰å †å å³å¯ã€‚</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">FC</span> <span class="p">(</span><span class="mi">784</span><span class="p">,</span><span class="mi">256</span><span class="p">)</span>
<span class="n">ReLU</span><span class="p">()</span>
<span class="n">FC</span> <span class="p">(</span><span class="mi">256</span><span class="p">,</span><span class="mi">128</span><span class="p">)</span>
<span class="n">ReLU</span><span class="p">()</span>
<span class="n">FC</span> <span class="p">(</span><span class="mi">128</span><span class="p">,</span><span class="mi">64</span><span class="p">)</span>
<span class="n">ReLU</span><span class="p">()</span>
<span class="n">FC</span> <span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>
<span class="n">Softmax</span><span class="p">()</span>
</code></pre></div></div>
<p>å’Œå‰é¢ä¸åŒçš„æ˜¯ï¼Œè¿™æ¬¡æˆ‘ä»¬è¦è§£å†³çš„æ˜¯ä¸€ä¸ªåˆ†ç±»é—®é¢˜ï¼Œå› æ­¤æˆ‘ä»¬çš„è¾“å‡ºæ˜¯<code class="highlighter-rouge">Softmax(x)</code>åçš„ç»“æœï¼Œè¿™ä¼šç›´æ¥å½±å“æˆ‘ä»¬çš„losså‡½æ•°çš„é€‰æ‹©ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨<code class="highlighter-rouge">nn.CrossEntropyLoss()</code>ã€‚ä½†æ ¹æ®<a href="https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss">æ–‡æ¡£</a></p>

<blockquote>
  <p>This criterion combines <code class="highlighter-rouge">nn.LogSoftmax()</code> and <code class="highlighter-rouge">nn.NLLLoss()</code> in one single class. The input is expected to contain scores for each class.</p>
</blockquote>

<p>æˆ‘ä»¬éœ€è¦å°†FCçš„è¾“å‡ºç›´æ¥ä¼ ç»™<code class="highlighter-rouge">CrossEntropyLoss()</code>,è€Œä¸æ˜¯softmaxçš„è¾“å‡ºã€‚å®é™…åº”ç”¨ä¸­ï¼Œæˆ‘ä»¬æ›´å¸Œæœ›å°†ä¸¤è€…åˆ†å¼€ï¼Œå› æ­¤è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨<code class="highlighter-rouge">nn.NLLLoss()</code>ã€‚ç¡®å®šäº†losså‡½æ•°åï¼Œæˆ‘ä»¬å¯ä»¥æµ‹è¯•ä¸‹æˆ‘ä»¬çš„model</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Classifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc4</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="c1"># Dropout module with 0.2 drop probability
</span>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="c1">#convert the input tensor to [64,784]
</span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc4</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Classifier</span><span class="p">()</span>
<span class="n">images</span><span class="p">,</span><span class="n">labels</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">trainloader</span><span class="p">))</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
</code></pre></div></div>
<p>è¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå¯¹äº<code class="highlighter-rouge">nn.LogSoftmax</code>æˆ‘ä»¬éœ€è¦æŒ‡å®š<code class="highlighter-rouge">dim</code>çš„å€¼ï¼Œ<code class="highlighter-rouge">dim=1</code>è¡¨ç¤ºæŒ‰rowè¿›è¡Œsumã€‚æˆ‘ä»¬å¯ä»¥è§‚å¯Ÿä¸€æ¨¡å‹çš„è¾“å‡º</p>

<p><img src="/assets/images/2019/07/pytorch-2-result-1.png" /></p>

<p>ç”±äºæˆ‘ä»¬çš„æ¨¡å‹è¿˜æœªç»è®­ç»ƒï¼Œå› æ­¤è¾“å‡ºç»“æœåŸºæœ¬å¯ä»¥è®¤ä¸ºæ˜¯ç­‰æ¦‚ç‡åˆ†å¸ƒï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬æŒ‰ç…§å‰é¢çš„æ–¹æ³•æ¥trainæˆ‘ä»¬çš„æ¨¡å‹</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.003</span><span class="p">)</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">5</span>
<span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">running_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">trainloader</span><span class="p">:</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span><span class="n">labels</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">"Traning loss: {running_loss}"</span><span class="p">)</span>
</code></pre></div></div>
<p>è¿­ä»£5æ¬¡åLossæ”¶æ•›åœ¨0.317ï¼Œæ­¤æ—¶æˆ‘ä»¬è·‘ä¸€å¼ æµ‹è¯•é›†çš„å›¾ç‰‡ï¼Œå¹¶è§‚å¯Ÿè¾“å‡ºç»“æœ</p>

<p><img src="/assets/images/2019/07/pytorch-2-result-2.png" /></p>

<h3 id="è§£å†³è¿‡æ‹Ÿåˆé—®é¢˜">è§£å†³è¿‡æ‹Ÿåˆé—®é¢˜</h3>

<p>ä»ä¸Šå›¾ä¸­çœ‹ï¼Œè²Œä¼¼æˆ‘ä»¬çš„æ¨¡å‹è¿˜ä¸é”™ï¼Œä½†æ˜¯æˆ‘ä»¬éœ€è¦ä¸€ä¸ªé‡åŒ–æŒ‡æ ‡æ¥è¡¡é‡æ¨¡å‹çš„å‡†ç¡®ç‡ï¼Œå¸¸è§çš„åšæ³•æ˜¯åœ¨æ¯ä¸€ä¸ªtraining loopç»“æŸæ—¶ï¼Œç”¨æˆ‘ä»¬çš„æµ‹è¯•é›†æµ‹è¯•ä¸€æ¬¡å¹¶è§‚å¯Ÿè¾“å‡ºç»“æœã€‚ç”±äºæ¯ä¸€å¼ å›¾ç‰‡ä¼šäº§ç”Ÿ10ä¸ªç»“æœï¼Œæˆ‘ä»¬åªå–æ¦‚ç‡æœ€é«˜çš„ä¸€é¡¹ï¼Œè€Œä¸€æ¬¡loopæœ‰64å¼ å›¾ç‰‡ï¼Œå› æ­¤æˆ‘ä»¬çš„ç»“æœæ˜¯ä¸€ä¸ª<code class="highlighter-rouge">[64,1]</code>çš„å‘é‡ã€‚</p>

<p>ä¸ºäº†å¾—åˆ°ä¸Šè¿°ç»“æœæˆ‘ä»¬è¦ç”¨åˆ°PyTorchä¸­çš„<code class="highlighter-rouge">topk</code>å‡½æ•°ï¼Œè¿™ä¸ªå‡½æ•°ä¼šè¿”å›æ¦‚ç‡ç”±é«˜åˆ°ä½çš„å‰kä¸ªç»“æœï¼Œå¯¹äºæˆ‘ä»¬çš„åœºæ™¯ï¼Œæˆ‘ä»¬åªéœ€è¦è¿”å›ç¬¬ä¸€ä¸ªï¼Œå› æ­¤ç”¨<code class="highlighter-rouge">topk(1,dim=1)</code>å³å¯ã€‚å¦å¤–ç”±äºæˆ‘ä»¬è¦å°†é¢„æµ‹ç»“æœå’Œæµ‹è¯•é›†ä¸­çš„labelåšæ¯”è¾ƒï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦ç¡®ä¿è¿™ä¸¤ä¸ªtensorçš„sizeæ˜¯ä¸€è‡´çš„</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">testloader</span><span class="p">))</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">))</span> <span class="c1">#convert the output tensor to [0,1]
</span><span class="n">top64</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1">#[64,1]
</span><span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="c1">#convert labels to [64.1]
</span></code></pre></div></div>
<p>ä¸Šè¿°ä»£ç å¯ä»¥ç¡®ä¿æˆ‘ä»¬çš„è¾“å‡ºç»“æœå¯ä»¥å’Œlabelçš„sizeä¸€è‡´ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬è¦è®¡ç®—å‡†ç¡®ç‡ï¼Œæ–¹æ³•å¾ˆç®€å•ï¼Œç”¨æ¯”è¾ƒç»“æœä¸ºtrueçš„æ•°é‡é™¤ä»¥ç»“æœæ•°é‡ï¼ˆ10ï¼‰å³å¯ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨<code class="highlighter-rouge">torch.mean</code></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">equals</span> <span class="o">=</span> <span class="n">top64</span> <span class="o">==</span> <span class="n">labels</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">equals</span><span class="o">.</span><span class="nb">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">))</span>
</code></pre></div></div>
<p>æœ‰äº†ä¸Šé¢çš„é“ºå«ï¼Œç°åœ¨æˆ‘ä»¬å¯ä»¥åœ¨è®­ç»ƒä¸­åŠ å…¥validationçš„ä»£ç </p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_loss</span> <span class="o">=</span> <span class="mi">0</span> 
<span class="n">accuracy</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">testloader</span><span class="p">:</span>
        <span class="n">log_ps</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
        <span class="n">test_loss</span> <span class="o">+=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">log_ps</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="c1">#è®¡ç®—test_loss
</span>        <span class="n">ps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_ps</span><span class="p">)</span>
        <span class="n">top_p</span><span class="p">,</span> <span class="n">top_class</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">equals</span> <span class="o">=</span> <span class="n">top_class</span> <span class="o">==</span> <span class="n">labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">top_class</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> 
        <span class="n">accuracy</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">equals</span><span class="o">.</span><span class="nb">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">))</span> <span class="c1">#è®¡ç®—accuracy
</span>
<span class="n">train_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">running_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">trainloader</span><span class="p">))</span>
<span class="n">test_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">testloader</span><span class="p">))</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Epoch: {}/{}.. "</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">e</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span><span class="p">),</span>
        <span class="s">"Training Loss: {:.3f}.. "</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">running_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">trainloader</span><span class="p">)),</span>
        <span class="s">"Test Loss: {:.3f}.. "</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">test_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">testloader</span><span class="p">)),</span>
        <span class="s">"Test Accuracy: {:.3f}"</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">accuracy</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">testloader</span><span class="p">)))</span>
</code></pre></div></div>
<p>è¿™ä¸€æ¬¡æˆ‘ä»¬å¢åŠ äº†epochså€¼ä¸º30ï¼Œç„¶åè§‚å¯ŸTraining Losså’ŒTest Lossä¸¤ä¸ªæŒ‡æ ‡çš„å˜åŒ–æƒ…å†µï¼Œå¦‚ä¸‹å›¾æ‰€ç¤º</p>

<p><img src="/assets/images/2019/07/pytorch-2-testing-1.png" /></p>

<p>æ˜¾ç„¶æˆ‘ä»¬çš„æ¨¡å‹å‡ºç°äº†è¿‡æ‹Ÿåˆï¼Œå³training errorä¸æ–­é™ä½ï¼Œä½†æ˜¯testing errorå´ä¸é™åå‡ã€‚ä¸ºäº†è§£å†³è¿‡æ‹Ÿåˆï¼Œå¸¸ç”¨æ‰‹æ®µæ˜¯å¼•å…¥Dropoutå±‚ï¼Œå³å¯¹å‚æ•°åšRegularizationã€‚ä¿®æ”¹æˆ‘ä»¬çš„modelï¼ŒåŠ å…¥dropout</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Classifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc4</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="c1"># Dropout module with 0.2 drop probability
</span>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc4</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>
</code></pre></div></div>
<p>å¼•å…¥Dropoutä¹‹åæˆ‘ä»¬è¿˜éœ€è¦ä¿®æ”¹ä¸€ä¸‹è®­ç»ƒä»£ç ï¼Œå½“æˆ‘ä»¬å¯¹æµ‹è¯•æ•°æ®åšforwardçš„æ—¶å€™ï¼Œéœ€è¦ç¦æ‰Dropoutï¼Œæˆ‘ä»¬è¦è°ƒä¸€ä¸‹<code class="highlighter-rouge">model.eval()</code>ï¼Œè€Œåœ¨ä¸‹æ¬¡trainingå¼€å§‹å‰ï¼Œæˆ‘ä»¬å†è°ƒä¸€ä¸‹<code class="highlighter-rouge">model.train()</code>æ¥å¼€å¯Dropoutï¼Œä»£ç å¦‚ä¸‹</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">model</span><span class="o">.</span><span class="nb">eval</span><span class="p">()</span> <span class="c1">#disable dropout
</span>        <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">testloader</span><span class="p">:</span>
            <span class="o">...</span>
            <span class="c1">#validation code
</span>            <span class="o">...</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span><span class="c1">#enable dropout
</span></code></pre></div></div>
<p>é‡æ–°è®­ç»ƒï¼Œè§‚å¯Ÿä¸Šè¿°ä¸¤ä¸ªæŒ‡æ ‡çš„å˜åŒ–æƒ…å†µï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚åŸºæœ¬ä¸Šæˆ‘ä»¬å¯ä»¥è®¤ä¸ºæˆ‘ä»¬çš„æ¨¡å‹å¯ä»¥æ­£å¸¸å·¥ä½œäº†ã€‚</p>

<p><img src="/assets/images/2019/07/pytorch-2-testing-2.png" /></p>

<h3 id="å°ç»“">å°ç»“</h3>

<p>è¿™ä¸ªä¾‹å­ä¸­æˆ‘ä»¬è®­ç»ƒäº†ä¸€ä¸ªç›¸å¯¹å¤æ‚ä¸€ç‚¹çš„ç¥ç»ç½‘ç»œï¼Œå¹¶è§£å†³äº†ä¸€ä¸ªå›¾ç‰‡åˆ†ç±»çš„é—®é¢˜ã€‚æˆ‘ä»¬ä½¿ç”¨Fully Connected Layerä½œä¸ºhidden layerï¼Œé€šè¿‡Softmaxå¯¹ç»“æœåˆ†ç±»ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å¹¶ä¸æ˜¯ä¸€ä¸ªCNNæ¨¡å‹ï¼Œè€Œæ˜¯å°†åƒç´ ç‚¹å…¨éƒ¨æ‰“æ•£åå°†æ¯ä¸ªåƒç´ ç‚¹ä½œä¸ºä¸€ä¸ªå•ç‹¬çš„featureã€‚è¿™ç§å®é™…ä¸ŠæŸå¤±äº†å›¾ç‰‡åœ¨spatialæ–¹é¢çš„ä¿¡æ¯ï¼Œåªé€‚ç”¨äºè¯†åˆ«ç®€å•çš„ï¼Œåˆ†è¾¨ç‡ä½çš„å›¾ç‰‡ã€‚å¯¹äºå¤æ‚é«˜åˆ†è¾¨ç‡çš„å›¾ç‰‡ï¼Œéœ€è¦ä½¿ç”¨CNNæ¥æ„å»ºæ¨¡å‹</p>

<p>æ€»ç»“ä¸€ä¸‹ä¸Šé¢çš„æ­¥éª¤</p>

<ol>
  <li>å‡†å¤‡æ•°æ®ï¼Œå¹¶å¯è§†åŒ–ã€‚è¿™ä¸€æ­¥å¯ä»¥ä½¿ç”¨PyTorchçš„<code class="highlighter-rouge">datasets</code>å’Œ<code class="highlighter-rouge">torch.utils.data.DataLoader</code></li>
  <li>å¯¹æ•°æ®åšé¢„å¤„ç†ï¼Œè¿™ä¸€æ­¥å¯ä»¥ä½¿ç”¨PyTorchçš„<code class="highlighter-rouge">transforms</code></li>
  <li>è®¾è®¡model</li>
  <li>é€‰å–Optimizerå’Œlosså‡½æ•°ï¼Œè®­ç»ƒ</li>
  <li>è§‚å¯Ÿtraining errorå’Œvalidation errorï¼Œå¹¶åœ¨validation erroråŒºåŸŸç¨³å®šæ—¶åœæ­¢training</li>
  <li>ç”¨æµ‹è¯•é›†æµ‹è¯•æˆ‘ä»¬çš„model</li>
</ol>

<h2 id="resoures">Resoures</h2>

<ul>
  <li><a href="https://livebook.manning.com/book/deep-learning-with-pytorch/welcome/v-10/">Deep Learning with PyTorch</a></li>
  <li><a href="https://www.udacity.com/course/deep-learning-pytorch--ud188">Intro to Deep Learning</a></li>
</ul>
:ET