I"t.<p>在Objective Detection上比较有名的model是R-CNN以它相关的变种。下面简略介绍一下其实现的思路</p>

<h3 id="r-cnn">R-CNN</h3>

<p>R-CNN是Region-based Convolutional Neural Networks的缩写。其主要的思路是</p>

<ol>
  <li>找一个Pre-trained的CNN network作为backbone</li>
  <li>通过selective search为一张图片生成约2000个RoI，每个RoI大小不同</li>
  <li>由于生成RoI尺寸大小不同，我们需要将它们warp成一个固定大小的矩形，作为后面CNN网络的输入。注意warp相当于对原矩形区域的图片进行缩放，而不是截取。</li>
  <li>将每一个warp后的RoI输入Pre-trained CNN model得到feature map (fc7)</li>
  <li>将feature map通过binary SVM classifier进行分类</li>
  <li>将类型判断正确的RoI进行通过一个bbox regression model进行校正。</li>
</ol>

<p>整个过程如下图所示</p>

<p><img src="/assets/images/2018/04/dl-cnn-3-r-cnn-1.png" /></p>

<p>R-CNN虽然能完成目标检测的任务，但是速度却非常的慢</p>

<ul>
  <li>有2000个region proposal, 训练需要84小时</li>
  <li>如果用vGG16，一次inference需要47s</li>
  <li>整个过程需要三个Model，一个feature extraction的CNN model，一个SVM的classifier和一个bounding box的regression model</li>
</ul>

<h3 id="fast-r-cnn">Fast R-CNN</h3>

<p>为了解决R-CNN的性能问题，Fast R-CNN将上面三个model整合成了一个。其流程为</p>

<ol>
  <li>找一个Pre-trained的CNN network作为backbone</li>
  <li>通过selective search为一张图片生成约2000个RoI，每个RoI大小不同</li>
  <li>调整Pre-trained的CNN model
    <ul>
      <li>将model最后一个max pooling layer替换为RoI pooling layer。RoI Pooling会输出一个组fixed-length的feature vectors</li>
      <li>将model最后一个FC+softmax(K classes)替换为 FC+softmax(K+1 classes)</li>
    </ul>
  </li>
  <li>model最后有两个输出，分别为
    <ul>
      <li>每个RoI的class概率</li>
      <li>一个bbox的regression model用来对RoI进行校正（按照class分类）</li>
    </ul>
  </li>
</ol>

<p><img src="/assets/images/2018/04/dl-cnn-3-fast-r-cnn.png" /></p>

<p>总的来说，<mark>Fast R-CNN最大的提升在于它对feature map的提取是一次完成的</mark>，而不像R-CNN需要将每一个RoI单独计算，这大大节省了计算资源，提高了计算速度。另一个需要掌握的重点是Fast R-CNN使用了RoI Pooling，其原理如下</p>

<p>我们首先为每张图片生成大概2000个RoI。然后用一个feature extractor(论文中使用的VGG16)的到feature maps。例如，一张<code class="highlighter-rouge">(1, 3, 512, 512)</code>的图片经过CNN网络后得到一组<code class="highlighter-rouge">(512, 3, 16, 16)</code>的feature map。</p>

<p><img src="/assets/images/2018/04/dl-cnn-3-fast-r-cnn-6.png" /></p>

<p>接下来我们要对从feature maps中提取RoI，由于我们之前生成的RoI尺寸是基于图片的原始尺寸<code class="highlighter-rouge">(512, 512)</code>，而此时的feature map的大小已经从<code class="highlighter-rouge">(512, 512)</code>变成了<code class="highlighter-rouge">(16, 16)</code>, 因此我们的RoI区域也要等比例缩小。例如一个<code class="highlighter-rouge">(x:296, y:192, h:145, w:200)</code>的bounding box在feature map中将变成<code class="highlighter-rouge">(x:9.25, y:6, h:4.53, w:6.25 )</code>如下图所示</p>

<p><img src="/assets/images/2018/04/dl-cnn-3-fast-r-cnn-4.png" /></p>

<p>此时我们发现bbox出现了小数，我们需要其quantize成整数，但是这会损失一部分数据，如下图三中的深蓝色部分所示</p>

<div class="md-flex-h md-flex-no-wrap md-margin-bottom-12">
<div><img src="/assets/images/2018/04/dl-cnn-3-fast-r-cnn-1.png" /></div>
<div class="md-margin-left-12"><img src="/assets/images/2018/04/dl-cnn-3-fast-r-cnn-2.png" /></div>
<div class="md-margin-left-12"><img src="/assets/images/2018/04/dl-cnn-3-fast-r-cnn-3.png" /></div>
</div>

<p>接下来我们要对RoI中的像素进行RoI Pooling，其目的是将各种大小不一的bbox映射成长度统一的vector以便进行后面的FC。具体做法是使用max pooling，还是上面的例子，经过quantization后，我们的bbox变成了<code class="highlighter-rouge">4x6</code>的，接下来我们用max pooling把它映射成<code class="highlighter-rouge">3x3</code>的，如下图所示</p>

<p><img src="/assets/images/2018/04/dl-cnn-3-fast-r-cnn-5.png" width="60%" /></p>

<p>上图中我们发现最下面一行数据也被丢弃掉了，这是由于在竖直方向上，4无法整除3。通过RoI Pooling我们可以得到一组<code class="highlighter-rouge">($roi,512,3,3)</code>的feature map，这也是后面FC层的输入，最终通过两层FC我们得到了两个输出结果，一个是RoI的class，另一个是RoI的bbox。</p>

<p>虽然Fast R-CNN可以在training和inference的速度上比R-CNN快，但生成region proposal仍然占据了大部分的时间</p>

<h3 id="faster-r-cnn">Faster R-CNN</h3>

<p>显然下一步的优化目标就是将region proposal也整合进网络，这也是Faster R-CNN的主要设计思路，具体来说</p>

<ol>
  <li>去掉了Selective Search，增加了一个RPN network来生成RoI</li>
  <li>引入了 anchor box的概念</li>
</ol>

<p><img src="/assets/images/2018/04/dl-cnn-3-faster-r-cnn.png" /></p>

<p>这里简单先介绍一下RPN的工作原理。假设我们的输入图片尺寸为<code class="highlighter-rouge">(800,800)</code>，经过VGG后，得到的feature map为<code class="highlighter-rouge">(512, 50, 50)</code>。接下来我们需要对每个feature map中的每个pixel生成9个bounding box</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">anchors_boxes_per_location</span> <span class="o">=</span> <span class="mi">9</span>
<span class="n">scales</span> <span class="o">=</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">]</span>
<span class="n">ratios</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>

<span class="c1"># (1,1)
</span><span class="n">ctr_x</span><span class="p">,</span> <span class="n">ctr_y</span> <span class="o">=</span> <span class="mi">16</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="mi">16</span><span class="o">/</span><span class="mi">2</span>
</code></pre></div></div>
<p>这样得到的每个bbox的size和ratio都不同。注意，我们虽然是在feature map上对<code class="highlighter-rouge">50 x 50</code>个点操作，但实际上生成的bbox的大小和位置却是相对于原输入图片的，如下图所示</p>

<p><img src="/assets/images/2018/04/dl-cnn-3-faster-r-cnn-1.png" /></p>

<h3 id="mask-r-cnn">Mask R-CNN</h3>

<p>Mask R-CNN是基于Faster R-CNN的架构，引入了Instant Segmentation。它除了输出目标物体的类型和bbox意外，还输出一个segmentation mask，其结构如下图所示</p>

<p><img src="/assets/images/2018/04/dl-cnn-3-mask-r-cnn.png" /></p>

<p>由于Mask R-CNN需要生成像素级别的mask，前面提到的RoI Pooling由于损失太多data因此精度大大降低。为了解决这个问题Mask R-CNN对上面RoI pooling的改进，提出了RoI Align。我们下面来重点介绍这个算法</p>

<p>前面已经知道RoI Pooling的两次quantization损失了很多data，RoI Align通过使用双线性二次插值弥补了这一点。还是以前面例子来说明，下图是我们前面的bbox，我们的目标还是对其进行3x3的RoI Pooling操作</p>

<p><img src="/assets/images/2018/04/dl-cnn-3-roi-align-1.png" /></p>

<p>和之前不同的是，我们此时不对x,y,w,h进行取整，而是将bbox分成3x3个格子，格子的宽高可以为小数，然后在每个格子内应用双线性插值，如下图所示</p>

<p><img src="/assets/images/2018/04/dl-cnn-3-roi-align-2.png" width="60%" /></p>

<p>首先我们在每个格子里取四个点，每个点的位置为格子长宽的三等分点，每个点的插值结果用下面公式计算，其中Q值为每个点对应的像素值</p>

<p><img src="/assets/images/2018/04/dl-cnn-3-roi-align-3.png" /></p>

<p>下面我们以左上角<code class="highlighter-rouge">(9.44, 6.50)</code>为例，看一下双线性插值是如何计算的。公式里的<code class="highlighter-rouge">x,y</code>分别对应<code class="highlighter-rouge">(9.44, 6.50)</code>。其中<code class="highlighter-rouge">(x1, x2, y1, y2)</code>分别对应四个点邻接cell的中心值，以<code class="highlighter-rouge">(9.44, 6.50)</code>为例，和它最近的cell的中心点为<code class="highlighter-rouge">(9.50, 6.50)</code>，因此<code class="highlighter-rouge">x1</code>为<code class="highlighter-rouge">9.5</code>,<code class="highlighter-rouge">y1</code>为<code class="highlighter-rouge">6.50</code>; 左下角点邻接cell的中心值为<code class="highlighter-rouge">(9.50, 7.50)</code>，由于<code class="highlighter-rouge">x1</code>没有发生变化还是<code class="highlighter-rouge">9.5</code>，而<code class="highlighter-rouge">y2</code>变成了<code class="highlighter-rouge">7.5</code>; 以此类推，我们可以得到右上和右下两个cell的中心点分别为 <code class="highlighter-rouge">(10.50, 6.50)</code>和<code class="highlighter-rouge">(10.50, 7.50)</code>，此时<code class="highlighter-rouge">x1,x2,y1,y2</code>的值均已确定，我们可以套用上面公式计算出<code class="highlighter-rouge">(x,y)</code>点处的值为<code class="highlighter-rouge">0.14</code>。</p>

<p><img src="/assets/images/2018/04/dl-cnn-3-roi-align-4.png" /></p>

<p>按照上述方式我们可以为剩余三个点计算其双线性插值结果，如下图所示</p>

<div class="md-flex-h md-flex-no-wrap md-margin-bottom-12">
<div class="md-margin-left-12"><img src="/assets/images/2018/04/dl-cnn-3-roi-align-5.png" /></div>
<div class="md-margin-left-12"><img src="/assets/images/2018/04/dl-cnn-3-roi-align-6.png" /></div>
<div class="md-margin-left-12"><img src="/assets/images/2018/04/dl-cnn-3-roi-align-7.png" /></div>
</div>

<p>当我们结算完这个4个点的双线性插值结果，我们便可以用max pooling得到该区域的RoI Align的结果。</p>

<p><img src="/assets/images/2018/04/dl-cnn-3-roi-align-8.png" /></p>

<p>重复上述步骤我们可以得到这RoI Region的结果，如下图所示</p>

<p><img src="/assets/images/2018/04/dl-cnn-3-roi-align-9.gif" /></p>

<p>理解了RoI Align之后，我们便可以和Fast R-CNN一样对所有的feature map进行RoI Align的操作，得到一组<code class="highlighter-rouge">($roi,512,3,3)</code>的feature map，作为后续layer的输入</p>

<div class="md-flex-h md-flex-no-wrap md-margin-bottom-12">
<div class="md-margin-left-12"><img src="/assets/images/2018/04/dl-cnn-3-roi-align-10.png" /></div>
<div class="md-margin-left-12"><img src="/assets/images/2018/04/dl-cnn-3-roi-align-11.png" /></div>
</div>

<p>和RoI Pooling相比，RoI Align利用了更多RoI Region周围的像素信息（上图中左边绿色部分），因此可以得到更准确的结果</p>

<h2 id="resources">Resources</h2>

<ul>
  <li><a href="https://towardsdatascience.com/understanding-region-of-interest-part-2-roi-align-and-roi-warp-f795196fc193">Understanding Region of Interest — (RoI Align and RoI Warp)</a></li>
  <li><a href="https://lilianweng.github.io/lil-log/2017/10/29/object-recognition-for-dummies-part-1.html#selective-search">Selective Search</a></li>
</ul>
:ET