---
list_title: GenAI | LLM Fine Tuning
title: LLM Fine Tuning
layout: post
categories: ["GenAI", "Transformer", "LLM"]
---

## Limitations of in-context learning

- May not work for samller models
- Examples take up space in the context window

## LLM fine-tuning at a high level

In contrast to pre-training, where you train the LLM using vast amounts of unstructured textual data via self-supervised learning, <mark>fine-tuning is a supervised learning process where you use a data set of labeled examples to update the weights of the LLM</mark>. The labeled examples are <mark>prompt completion pairs</mark>, the fine-tuning process extends the training of the model to improve its ability to generate good completions for a specific task.

<img class="md-img-center" src="{{site.baseurl}}/assets/images/2024/llm2-1.png">

One strategy, known as <mark>instruction fine tuning</mark>, is particularly good at improving a model's performance on a variety of tasks.

### Fine Tuning using prompts

Instruction fine-tuning trains the model using examples that demonstrate how it should respond to a specific instruction

<img class="md-img-center" src="{{site.baseurl}}/assets/images/2024/llm2-2.png">

For example, if you want to fine tune your model to improve its summarization ability, you'd build up a data set of examples that begin with the instruction summarize, the following text or a similar phrase. And if you are improving the model's translation skills, your examples would include instructions like translate this sentence.

<img class="md-img-center" src="{{site.baseurl}}/assets/images/2024/llm2-3.png">

These prompt completion examples allow the model to learn to generate responses that follow the given instructions.

Instruction fine-tuning, where all of the model's weights are updated is known as <mark>full fine-tuning</mark>. The process results in a new version of the model with updated weights
