---
list_title: Note | MIT 6.172 (12) - Parallel Storage Allocation
title: Parallel Storage Allocation
layout: post
mathjax: true
---

### Heap Storage in C

- Allocation

`void* malloc(size_t s);` - allocate and return a pointer to a block of memory containing at least `s` bytes.

- Aligned allocation

`void* memalign(size_t a, size_t s);` - allocate and return a pointer to a block of memory containing at least `s` bytes, aligned to a multiple of `a` where `a` must be an exact power of `2`: `0 == ((size_t)memalign(a, s)) % a`. One reason to use `memalign` is to align the memory allocation to cache line to reduce the number of times of cache misses. Another reason is that the vectorization operations also requires the memory addresses to aligned with power of 2.

- Deallocation

`void free(void *p);` - `p` is a pointer to a block of memory returned by `malloc()` or `memalign()`. Deallocate the block.

### Allocating Virtual Memory

The `mmap()` system call can be used to allocate virtual memory by <mark>memory mapping</mark>. It usually used to treat some files on the disk as part of memory, so that when you write to that memory region it also backs it up on the disk. In this case, we're using `mmap` to allocate virtual memory without having any backing file.

<img class="md-img-center" src="{{site.baseurl}}/assets/images/2021/08/perf-sa-11.png">

- The first param means where I want to allocate the memory. `0` means don't care.
- The second params indicates how much memory I want to allocate in bytes.
- The thrid params is the permissions.
- `MAP_PRIVATE` means the memory is private to the process that's allocating it. `MAP_ANON` means there is no name associated with the memory region

The Linux kernel finds a contiguous, unused region in the address space of the application large enough to hold size bytes, modifies the page table, and creates the necessary virtual-memory management structures within the OS to make the user’s accesses to this area "legal" so that accesses won’t result in a segfault.

### Properties of `mmap()`

- `mmap()` is lazy. It does not immediately allocate physical memory for the requested allocation.
- Instead, it populates the page table with entries pointing to a special zero page and marks the page as read only.
- The first write into such a page causes a page fault.
- At that point, the OS allocates a physical page, modifies the page table, and restarts the instruction.
- You can `mmap()` a terabyte of virtual memory on a machine with only a gigabyte of DRAM.
- A process may die from running out of physical memory well after after the mmap() call.

### What's the difference between `malloc()` and `mmap()`

- The functions `malloc()` and `free()` are part of the memory-allocation interface of the heap-management code in the C library.
- The heap-management code uses available system facilities, including `mmap()`, to obtain memory (virtual address space) from the kernel.
- The heap-management code within `malloc()` attempts to satisfy user requests for heap storage by reusing freed memory whenever possible.
- When necessary, the `malloc()` implementation invokes mmap() and other system calls to expand the size of the user’s heap storage.

<mark>Q: Why just use `mmap` instead?</mark>

One anwser is that you might have free storage from before that you would want to reuse. It turns out that `mmap` is relatively heavy weight. It works on a page granularity. So if you wnat to do a small allocation, it's quite wasteful to allocate an entire page for that allocation and not reuse it. You'll get very bad external fragmentation. It also goes through all of the overhead of security of the OS and updaing the page table and so on. Whereas, use `malloc` is pretty fast for most allocations, and especially if you have temporal locality where you allocate something that you just recently freed. So your program will be pretty slow if you use `mmap` all the time even for small allocations.

### Address Translation

When you access memory location, you access via the virtual address, which can be divieded into two parts, where the lower order bits store the offset and higher order bits store the virtual page numeber.

<img class="md-img-center" src="{{site.baseurl}}/assets/images/2021/08/perf-sa-12.png">

If the virtual page does not reside in physical memory, a **page fault** occurs. When that happens,the OS will see that the process acutally has permissions to look at the memory region, and it will set the permissions and place the entry into the page table so that you can get the appropriate physical address. Otherwise, you'll get a **segmentation fault**.

Since page-table lookups are costly, the hardware contains a translation lookaside buffer (TLB) to cache recent page-table lookups. The page-table store pages which are typically 4kb. Nowadays, there are also huge pages, which can be a couple of megabytes. And most of the accesses in your program are going to be near each other. So they're likely going to reside on the same page for accesses that have been done close together in time. Therefore, you'll expect that many of your recent accesses are going to be stored in the TLB if your program has locality, either spatial or temporal locality or both.

So how this architecture works is that

1. The processors check whether the virtual address you're looking for is in TLB. If it's not, it's going to go to the page table and look it up. And then if it finds that there, then it's going to store that entry into the TLB.
2. Next, it's going to get this physical address that it found from the TLB and look it up into the CPU cache. If it finds it there, it gets it. If it doesn't, then it goes to DRAM to satisfy the request. 

Most of modern machines acutally have an optimization that allow you to do TLB accesses in parallel with the L1 cache access. So the L1 cache acutally uses virtual addresses instead of Physical addresses, and this reduces the latency of a memory access.

### Traditional Linear Stack

So when you execute a serial c and c++ program, you're using a stack to keep track of the function calls and local variables that you have to save. An execution of a serial C/C++ program can be viewed as a serial walk of an invocation tree. 

In the example below, we have function `A` calls function `B` and `C`, function `C` calls `D` and `E`

<img class="md-img-center" src="{{site.baseurl}}/assets/images/2021/08/perf-sa-13.png">

**Rule for pointers**: A parent can pass pointers to its stack variables down to its children, but not the other way around.

## Resource 

- [Perforamnce Engineering of Software Systems](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-172-performance-engineering-of-software-systems-fall-2018/index.htm)