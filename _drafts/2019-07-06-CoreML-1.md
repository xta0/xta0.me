---
layout: post
list_title: 聊聊CoreML | Overview of CoreML
title: 聊聊CoreML
categories: [Machine Learning, iOS, CoreML]
---

### Motivation

2017年的WWDC上Apple推出了自己的ML的framework - CoreML，它包含两部分，一部分是**CoreMl.framework**，另一部分是**mlmodel**。如果从整个ML的生态系统来看，CoreML实际上并不属于主流范畴，它属于on-device ML的一个分支，也就是所谓的边缘计算。早期的CoreML或者Google家的Tensor Flow lite在终端上基本上只能做Inference，而且model还不能太复杂。今年的WWDC上，CoreML有了比较大的更新，可以支持transfer learning。虽然现在还看不出这个特性除了在保护隐私方面外还有什么优势，毕竟单台设备所能产生的数据量有限，而从多台设备收集数据又会有隐私的问题。但眼看着5G物联网时代的到来，说不定ML在on-device这个领域会有些变革。因此，还是有必要关注下这方面的趋势的。

### CoreML的优势和劣势

先说说CoreML的优势

- API简单易用，对Apple的开发者友好
- mlmodel有一套完整的工具链，且标准开放 （虽说转换门槛还是有些的）
- 支持多种backend，包括CPU，GPU以及Apple自家的neural engine，可以根据model来做出最优选择
- 在A12或A12X上使用Neural Engine要比使用GPU (MPS)快很多，性能优势明显

再说说CoreML的劣势

- CoreML只能使用内置的operator，不能根据model进行定制，灵活性不太够，增加新的operator只能依赖iOS的SDK更新
- 性能不稳定，有些model运行的速度很快，有些很慢
- CoreML是一个黑盒而且不开源，不清楚内部是怎么实现的
- model的加密做的不够，很容易被逆向

### CoreML的版本

虽然CoreML在2017年的时候才出来，但到目前已经迭代了多个版本，我们可以通过下面代码来查看mlmodel所支持的版本

```python
import coremltools
spec = coremltools.utils.load_spec("MobileNet.mlmodel")
```
从目前得到的信息来看，mlmodel现在有4个版本

- **version 1&2**

第一个版本是2017年公布的，支持

1. model支持16bit的float weight
2. model支持自定义的layer

- **version 3 (CoreML 2)**

mlmodel的第三个版本是2018年WWDC发布CoreML 2的时候发布的，它支持

1. quantized weight
2. flexible image sizes and input shapes
3. MLSequence for dealing with sequential data and RNNs
4. batch predictions
5. custom models
    - BayesianProbitRegressor
    - TextClassifier
    - VisionFeaturePrint
    - WordTagger
    - NonMaximumSuppression

- **version 4**

今年的WWDC，Apple退出了CoreML 3，增加了下面的功能

1. 增加了几种新的model和Framework
    - K-Nearest Neighbors
    - ItemSimilarityRecommender
    - SoundAnalysisPreprocessing
    - Gazetteer
    - WordEmbedding
    - Linked models
2. 支持transfer learning，但是条件比较苛刻，从model的源码来看，只有下面四种model支持on-device update
    - NeuralNetworkClassifier
    - NeuralNetworkRegressor
    - NeuralNetwork
    - KNearestNeighborsClassifier
3. 增加了新的operator
4. NN支持任意shape的tensor
5. Dynamic graphs，支持for-loop或者if语句的

实事求是的讲，在整个on-device ML的生态上，CoreML还是做的很不错的，无论是性能，model的种类等。但基本上还是延续了Apple的老套路，走闭源，封闭的体系。

### CoreML Model

CoreML的model格式为`.mlmodel`，属于Apple自家的标准。如果我们将上面代码中的`spec`打印出来，则可以看到上面的MobileNet的结构

```python
print(spec.specificationVersion)

specificationVersion: 1
description {
    ...
}
neuralNetworkClassifier {
  layers {
    name: "conv1"
    input: "image"
    output: "conv1_1conv1/bn"
    convolution {
     ...
    }
  }
  layers {
    name: "conv1/bn"
    input: "conv1_1conv1/bn"
    output: "conv1_2conv1/scale"
    batchnorm {
     ...
    }
  }
  layers {
    name: "prob"
    input: "fc7"
    output: "classLabelProbs"
    softmax {
    } 
  }
  ...
```
基本上model的spec信息包含了model的结构以及用到了那些Operator，包括layer的类型，参数等。

### Model Format

进一步看，上述的信息是如何保存在model中的呢？mlmodel使用protobuf来序列化model的数据，

## 计算引擎

CoreML的计算引擎准确来说有三种，第一种显然就是CPU了，对应API封装在了Accelerate Framework中；第二种是GPU，其计算引擎主要通过Metal Shader提供；最后一种是Apple独家的Neural Engine，即专门为机器学习设计的硬件芯片，目前API并不对开发者开放，但是我们或许可以通过Hopper来反汇编。

### Metal

Apple在2017年推出了Metal2，继续取代OpenGL作为自家设备上的GPU编程语言


WWDC中有关Metal在机器学习的视频

- [Using Metal2 For Comupte](https://developer.apple.com/videos/play/wwdc2017/608/)
- [Metal For Accelerating Machine Learning]()
- [Metal For Machine Learning]()


## Resources

- [CoreML model](https://apple.github.io/coremltools/coremlspecification/index.html)  
- [Apple CoreML models](https://developer.apple.com/machine-learning/models/)
- [](https://machinethink.net/blog/apple-deep-learning-bnns-versus-metal-cnn/)
